{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moteur de recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce notebook est de réaliser le moteur de recherche. La base de donnée sur laquelle l'on s'appuie est déjà sous la bonne forme (avec le notebook Initialisation). Ainsi on va mettre en place une fonction qui sera appelée à chaque requête du client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à faire si besoin\n",
    "#nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df=pd.read_csv(\"metadata_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "stop=stopwords.words('english')\n",
    "\n",
    "def preprocessing(x): #tokenisation,stop-words,lemmatization ...\n",
    "    clean = re.sub(r'['+string.punctuation + '’—”'+']', \"\", x.lower())\n",
    "    clean_text= re.sub(r'\\W+', ' ', clean)\n",
    "    a=\"\"\n",
    "    for i in clean_text.split():\n",
    "        if i not in stop :\n",
    "            a+=str(lemmatizer.lemmatize(i))+' '\n",
    "    return a\n",
    "\n",
    "def preprocessing_title(x): #tokenisation,stop-words,lemmatization ...\n",
    "    clean = re.sub(r'['+string.punctuation + '’—”'+']', \"\", x.lower())\n",
    "    clean_text= re.sub(r'\\W+', ' ', clean)\n",
    "    a=\"\"\n",
    "    for i in clean_text.split():\n",
    "        a+=str(lemmatizer.lemmatize(i))+' '\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(keywords,text): #keywords est une phrase\n",
    "    keys=preprocessing(keywords).split()\n",
    "    text=str(text)\n",
    "    if text==\"NaN\": #élimine \n",
    "        return -1\n",
    "    a=text.split()\n",
    "    if len(a)==0:\n",
    "        return 0\n",
    "    c=0\n",
    "    for i in a:\n",
    "        if i in keys:\n",
    "            c+=1\n",
    "    \n",
    "    return c/len(a)\n",
    "\n",
    "def counter_title(keywords,text): #keywords est une phrase\n",
    "    keys=preprocessing_title(keywords).split()\n",
    "    text=str(text)\n",
    "    if text==\"NaN\":\n",
    "        return -1\n",
    "    a=text.split()\n",
    "    if len(a)==0:\n",
    "        return 0\n",
    "    c=0\n",
    "    for i in keys:\n",
    "        if i in a:\n",
    "            c+=1\n",
    "    \n",
    "    return c/len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_note(data,keywords):#data est un df\n",
    "    data[\"freq_title\"]=data[\"title_process\"].apply(lambda x:counter_title(keywords,x))\n",
    "    data[\"freq_abstract\"]=data[\"abstract_process\"].apply(lambda x:counter(keywords,x))\n",
    "    data[\"note\"]=data[[\"freq_title\",\"freq_abstract\",\"note_date\",\"note_ref\"]].apply(lambda x: x[\"freq_title\"]+x[\"freq_abstract\"]+x[\"note_ref\"]+x[\"note_date\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "give_note(meta_df,\"risk factor smoking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.sort_values(by=[\"note\"],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
