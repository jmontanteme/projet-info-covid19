{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'un tableau récapitulatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de construire un pandas de taille (sous forme de matrice (nombre d'articles, nombres de champs lexicaux * 6) qui pour tous les articles récapitule ses \"performances\" dans différentes catégories, et ce pour chaque champ lexical déterminé à l'avance. \n",
    "\n",
    "Commençons par définir ces champs lexicaux, qui correspondent à des facteurs de risques. Ceux-ci sont suggérés par le site Kaggle (d'où est extraite la base de données). \n",
    "Ces facteurs sont : \n",
    "- Hypertension\n",
    "- Diabetes\n",
    "- Male gender\n",
    "- Heart Disease\n",
    "- COPD and respiratory system diseases\n",
    "- Smoking Status\n",
    "- Age\n",
    "- Cerebrovascular disease\n",
    "- Cardio- and cerebrovascular disease\n",
    "- Cancer\n",
    "- Chronic kidney diseases\n",
    "- Drinking\n",
    "- Overweight or obese\n",
    "- Chronic liver disease\n",
    "\n",
    "Il faut maintenant créer un \"champ lexical\" relatif à chacun de ces thèmes. Il est important d'avoir suffisament de synonymes pour ne pas manquer d'oublier des termes dans les articles. Ces derniers étant prétraités en amont, inutiles de faire attention aux majuscules et aux tirets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertension = ['hypertension', 'high blood pressure', 'hypertensive', 'high pressure', 'raised blood pressure', 'htn', 'hbp', 'ht', 'ace inhibitor', 'sartan']\n",
    "diabetes = ['diabetes', 'high blood sugar', 'insulin resistance', 'diabetic', 'diabetics', 'dm']\n",
    "gender = ['male gender', 'male', 'gender', 'sex', 'masculine', 'female']\n",
    "heart_disease = ['cardiopathy', 'heart disease', 'heart', 'chd', 'arrhythmia', 'tachycardia', 'bradycardia', 'fibrillation', 'cardiomyopathy', 'infarction', 'ischemic heart disease']\n",
    "COPD_respiratory_system = ['copd', 'emphysema', 'bronchitis', 'asthma', 'bronchiectasis', 'respiratory', 'trachea', 'lung', 'lungs', 'pulmonary', 'pneumoniae', 'pharyngitis', 'bronchiolitis', 'bronchopneumonia' ]\n",
    "smoking_status = ['smoking', 'smoke', 'smoker', 'tobacco']\n",
    "age = ['age', 'old', 'young', 'senior', 'child', 'children']\n",
    "cerebrovascular_disease = ['cerebrovascular', 'embolism', 'ischemic', 'stroke', 'aneurysm', 'tia']\n",
    "cancer = ['cancer', 'leukemia', 'cancerology', 'lymphom']\n",
    "kidney_disease = ['kidney', 'gfr', 'dialysis']\n",
    "drinking = ['drinking', 'alcohol', 'alcoholic']\n",
    "overweight = ['overweight', 'obesity', 'obese', 'bmi']\n",
    "liver_disease = ['liver', 'fascioliasis', 'cirrhosis', 'hepatitis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de travailler sur des textes le plus efficacement possible, on va procéder à un prétraitement qui consiste :\n",
    "- à récupérer les données nécessaires dans le dataset\n",
    "- à en extraire texte, titre, abstract, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "nlp = spacy.blank('en')\n",
    "nlp.max_length = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hta_tokens_list = [nlp(factor) for factor in hypertension]\n",
    "diabetes_tokens_list = [nlp(factor) for factor in diabetes]\n",
    "gender_tokens_list = [nlp(factor) for factor in gender]\n",
    "heart_tokens_list = [nlp(factor) for factor in heart_disease]\n",
    "respi_tokens_list = [nlp(factor) for factor in COPD_respiratory_system]\n",
    "smoking_tokens_list = [nlp(factor) for factor in smoking_status]\n",
    "age_tokens_list = [nlp(factor) for factor in age]\n",
    "cerebrovascular_tokens_list = [nlp(factor) for factor in cerebrovascular_disease]\n",
    "cancer_tokens_list = [nlp(factor) for factor in cancer]\n",
    "kidney_tokens_list = [nlp(factor) for factor in kidney_disease]\n",
    "drinking_tokens_list = [nlp(factor) for factor in drinking]\n",
    "overweight_tokens_list = [nlp(factor) for factor in overweight]\n",
    "liver_tokens_list = [nlp(factor) for factor in liver_disease]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliettemontanteme/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "root_path = '/Users/juliettemontanteme/Desktop/data_covid'\n",
    "#astuce : pour trouver facilement le chemin, ouvrir le dossier correspondant \n",
    "#et en appuyant sur \"alt\" aller sur édition et copier le chemin\n",
    "metadata_path = f'{root_path}/metadata.csv'\n",
    "meta_df = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138794"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classe permettant de faire un preprocessing d'un texte\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.article = \"\"\n",
    "        self.text = \"\"\n",
    "        self.text1 = \"\"\n",
    "        self.text2 = \"\"\n",
    "        self.title = \"\"\n",
    "        self.abstract = \"\"\n",
    "    def open_article(self):\n",
    "        file=open(str(root_path)+\"/\"+str(path),'r')\n",
    "        article=json.load(file)\n",
    "        file.close()\n",
    "        self.article = article\n",
    "    def make_text(self):\n",
    "        text_list = []\n",
    "        for entry in self.article['body_text']:\n",
    "            text_list.append(entry['text'])\n",
    "            text_list.append(\"\\n\")\n",
    "        text_full=''.join(text_list)\n",
    "        self.text = text_full\n",
    "        self.title = nlp(self.article['metadata']['title'])\n",
    "        self.abstract = nlp(meta_df_full_text.loc[lambda df: df['title'] == title] ['abstract'].to_numpy()[0])\n",
    "    \n",
    "    def preprocess(self): \n",
    "        self.text1 = nlp(self.text)\n",
    "        text2 = \"\"\n",
    "        for token in self.text1: \n",
    "            if token.is_stop == False:\n",
    "                text2 = text2 + \" \" + token.lemma_\n",
    "        self.text2 = nlp(text2)\n",
    "\n",
    "    def repr_1(self):\n",
    "        return(self.text1)\n",
    "    \n",
    "    def repr_2(self):\n",
    "        return(self.text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. La \"diffusivité\" d'un thème dans un article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de cette partie est de travailler sur un corpus restreint de textes comportant déjà un mot-clé (ou un groupe de mots clés) correspondant à un facteur de risque et éventuellement prétraités. On parcourt chaque texte (titre et abstract inclus) et pour chaque texte, on sauvegarde les positions des mots choisis. On calcule ensuite la moyenne et l'écart-type de la position du mot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class Diffusivity:\n",
    "    def __init__(self, matches, doc):\n",
    "        self.matches = matches\n",
    "        self.doc = doc\n",
    "        self.positions = []\n",
    "        self.occurence = len(self.matches)\n",
    "        self.score = 0\n",
    "    def position(self):\n",
    "        if self.matches != []:\n",
    "            for match in self.matches :\n",
    "                pos = (match[1] + match[2])/2\n",
    "                self.positions.append(int(pos))   \n",
    "    def scoring(self):\n",
    "        if self.positions != []:\n",
    "            mean_pos = np.mean(self.positions)\n",
    "            ecart_pos = math.sqrt(np.var(self.positions))\n",
    "            self.score = ecart_pos / len(self.doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère que lorsque l'écart type est plus grand que la moitié du nombre de mots du texte, cela veut dire que le mot-clé est cité dans plus de la moitié de l'article et donc que l'article parle principalement du mot-clé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2837764272295505"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = path_list[0]\n",
    "proc = Preprocess(path)\n",
    "proc.open_article()\n",
    "proc.make_text()\n",
    "proc.preprocess()\n",
    "doc = proc.text1\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "matcher.add(\"RESPI\", respi_tokens_list)\n",
    "match = matcher(doc)\n",
    "dif = Diffusivity(match, doc)\n",
    "dif.position()\n",
    "dif.scoring()\n",
    "dif.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. La fréquence d'un mot dans un groupe de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, on peut travailler sur un texte, sur un titre ou un abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frequency: \n",
    "    def __init__(self, matches, doc):\n",
    "        self.matches = matches\n",
    "        self.doc = doc\n",
    "        self.occurence = len(self.matches)\n",
    "        self.score = 0\n",
    "\n",
    "    def scoring(self):\n",
    "        if len(self.matches) != 0:\n",
    "            self.score = len(self.matches)/len(self.doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processus de notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_full_text(x):\n",
    "    if x[\"pdf_json_files\"]==True and x[\"pmc_json_files\"]==True:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_bool=meta_df[[\"pdf_json_files\",\"pmc_json_files\"]].isnull()\n",
    "meta_bool[\"has_full\"]=meta_bool.apply(lambda x:has_full_text(x),axis=1)\n",
    "meta_df_full_text=meta_df.loc[meta_bool[\"has_full\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(meta_df_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = []\n",
    "for i in range(n):\n",
    "    path = meta_df_full_text.iloc[i]['pmc_json_files']\n",
    "    if str(path)[0] == 'd':\n",
    "        path_list.append(path)\n",
    "    else :\n",
    "        path = meta_df_full_text.iloc[i]['pdf_json_files'].split(\";\")[0]\n",
    "        path_list.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scoring:\n",
    "    def __init__(self, path, lex, lex_name):\n",
    "        self.path = path\n",
    "        self.lex = lex\n",
    "        self.lex_name = lex_name\n",
    "        self.match_doc = []\n",
    "        self.match_title = []\n",
    "        self.match_abstract = []\n",
    "        self.doc = \"\"\n",
    "        self.score_dif = 0\n",
    "        self.title = \"\"\n",
    "        self.abstract = \"\"\n",
    "        self.score_fr_doc = 0\n",
    "        self.score_fr_title = 0\n",
    "        self.score_fr_abstract = 0\n",
    "        self.score_dif = 0\n",
    "    def matching(self):\n",
    "        proc = Preprocess(self.path)\n",
    "        proc.open_article()\n",
    "        proc.make_text()\n",
    "        proc.preprocess()\n",
    "        self.doc = proc.repr_1()\n",
    "        self.title = proc.title\n",
    "        self.abstract = proc.abstract\n",
    "        matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "        matcher.add(self.lex_name, self.lex)\n",
    "        self.match_doc = matcher(self.doc)\n",
    "        self.match_title = matcher(self.title)\n",
    "        self.match_abstract = matcher(self.abstract)\n",
    "        \n",
    "    def scoring(self):\n",
    "        #Calcul du score de diffusivité\n",
    "        dif = Diffusivity(self.match_doc, self.doc)\n",
    "        dif.position()\n",
    "        dif.scoring()\n",
    "        self.score_dif = dif.score\n",
    "        #Calcul du score de fréquence dans le texte\n",
    "        fr_doc = Frequency(self.match_doc, self.doc)\n",
    "        fr_doc.scoring()\n",
    "        self.score_fr_doc = fr_doc.score\n",
    "        #Calcul du score de fréquence dans le titre\n",
    "        fr_title = Frequency(self.match_title, self.title)\n",
    "        fr_title.scoring()\n",
    "        self.score_fr_title = fr_title.score\n",
    "        #Calcul du score de fréquence dans l'abstract\n",
    "        fr_abstract = Frequency(self.match_abstract, self.doc)\n",
    "        fr_abstract.scoring()\n",
    "        self.score_fr_abstract = fr_abstract.score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_list[0]\n",
    "proc = Preprocess(path)\n",
    "proc.open_article()\n",
    "proc.make_text()\n",
    "proc.preprocess()\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "matcher.add(\"RESPI\", respi_tokens_list)\n",
    "match = matcher(doc)\n",
    "dif = Diffusivity(match, doc)\n",
    "dif.position()\n",
    "dif.scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30831900241799925 0.002888917295155311 0 3.408751970684733e-05\n"
     ]
    }
   ],
   "source": [
    "path = path_list[51]\n",
    "sc = Scoring(path, respi_tokens_list, \"RESPI\")\n",
    "sc.matching()\n",
    "sc.scoring()\n",
    "print(sc.score_dif, sc.score_fr_doc, sc.score_fr_title, sc.score_fr_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliettemontanteme/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/juliettemontanteme/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/juliettemontanteme/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/juliettemontanteme/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/juliettemontanteme/Desktop/data_covid/document_parses/pmc_json/PMC3694918.xml.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-2f4273aa4a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmeta_df_full_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'Diffusivité {lex_name}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_dif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-fe6e4b91aa19>\u001b[0m in \u001b[0;36mmatching\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-19da02a61836>\u001b[0m in \u001b[0;36mopen_article\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0marticle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/juliettemontanteme/Desktop/data_covid/document_parses/pmc_json/PMC3694918.xml.json'"
     ]
    }
   ],
   "source": [
    "tokens_list = [hta_tokens_list, diabetes_tokens_list, gender_tokens_list, heart_tokens_list,respi_tokens_list, smoking_tokens_list, age_tokens_list, cerebrovascular_tokens_list, cancer_tokens_list, kidney_tokens_list, drinking_tokens_list, overweight_tokens_list, liver_tokens_list] \n",
    "tokens_names = [\"HTA\", \"DIABETES\", \"GENDER\", \"HEART\", \"RESPI\", \"SMOKING\", \"AGE\", \"CEREBROVASCULAR\", \"CANCER\", \"KIDNEY\", \"DRINKING\", \"OVERWEIGHT\", \"LIVER\"]\n",
    "for i in range(13):\n",
    "    lex = tokens_list[i]\n",
    "    lex_name = tokens_names[i]\n",
    "    for path in path_list:  \n",
    "        sc = Scoring(path, lex, lex_name)\n",
    "        sc.matching()\n",
    "        sc.scoring()\n",
    "        meta_df_full_text[f'Diffusivité {lex_name}'] = sc.score_dif\n",
    "        meta_df_full_text[f'FreqTitre {lex_name}'] = sc.score_fr_title\n",
    "        meta_df_full_text[f'FreqAbstrac {lex_name}'] = sc.score_fr_abstract\n",
    "        meta_df_full_text[f'FreqTexte {lex_name}'] = sc.score_fr_doc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/juliettemontanteme/Desktop/data_covid/document_parses/pmc_json/PMC3694918.xml.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-0663c4e97fb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'document_parses/pmc_json/PMC3694918.xml.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespi_tokens_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RESPI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_dif\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_fr_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_fr_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_fr_abstract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-fe6e4b91aa19>\u001b[0m in \u001b[0;36mmatching\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-19da02a61836>\u001b[0m in \u001b[0;36mopen_article\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0marticle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/juliettemontanteme/Desktop/data_covid/document_parses/pmc_json/PMC3694918.xml.json'"
     ]
    }
   ],
   "source": [
    "path = 'document_parses/pmc_json/PMC3694918.xml.json'\n",
    "sc = Scoring(path, respi_tokens_list, \"RESPI\")\n",
    "sc.matching()\n",
    "sc.scoring()\n",
    "print(sc.score_dif, sc.score_fr_doc, sc.score_fr_title, sc.score_fr_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>...</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>s2_id</th>\n",
       "      <th>Diffusivité HTA</th>\n",
       "      <th>FreqTitre HTA</th>\n",
       "      <th>FreqAbstrac HTA</th>\n",
       "      <th>FreqTexte HTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>d1aafb70c066a2068b02786f8929fd9c900897fb</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>10.1186/1471-2334-1-6</td>\n",
       "      <td>PMC35282</td>\n",
       "      <td>11472636.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>2001-07-04</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/d1aafb70c066a2068b027...</td>\n",
       "      <td>document_parses/pmc_json/PMC35282.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>02tnwd4m</td>\n",
       "      <td>6b0567729c2143a66d737eb0a2f63f2dce2e5a7d</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "      <td>10.1186/rr14</td>\n",
       "      <td>PMC59543</td>\n",
       "      <td>11667967.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>2000-08-15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/6b0567729c2143a66d737...</td>\n",
       "      <td>document_parses/pmc_json/PMC59543.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ejv2xln0</td>\n",
       "      <td>06ced00a5fc04215949aa72528f2eeaae1d58927</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
       "      <td>10.1186/rr19</td>\n",
       "      <td>PMC59549</td>\n",
       "      <td>11667972.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
       "      <td>2000-08-25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/06ced00a5fc04215949aa...</td>\n",
       "      <td>document_parses/pmc_json/PMC59549.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2b73a28n</td>\n",
       "      <td>348055649b6b8cf2b9a376498df9bf41f7123605</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Role of endothelin-1 in lung disease</td>\n",
       "      <td>10.1186/rr44</td>\n",
       "      <td>PMC59574</td>\n",
       "      <td>11686871.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Endothelin-1 (ET-1) is a 21 amino acid peptide...</td>\n",
       "      <td>2001-02-22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/348055649b6b8cf2b9a37...</td>\n",
       "      <td>document_parses/pmc_json/PMC59574.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9785vg6d</td>\n",
       "      <td>5f48792a5fa08bed9f56016f4981ae2ca6031b32</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "      <td>10.1186/rr61</td>\n",
       "      <td>PMC59580</td>\n",
       "      <td>11686888.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Respiratory syncytial virus (RSV) and pneumoni...</td>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/5f48792a5fa08bed9f560...</td>\n",
       "      <td>document_parses/pmc_json/PMC59580.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       sha source_x  \\\n",
       "0  ug7v899j  d1aafb70c066a2068b02786f8929fd9c900897fb      PMC   \n",
       "1  02tnwd4m  6b0567729c2143a66d737eb0a2f63f2dce2e5a7d      PMC   \n",
       "2  ejv2xln0  06ced00a5fc04215949aa72528f2eeaae1d58927      PMC   \n",
       "3  2b73a28n  348055649b6b8cf2b9a376498df9bf41f7123605      PMC   \n",
       "4  9785vg6d  5f48792a5fa08bed9f56016f4981ae2ca6031b32      PMC   \n",
       "\n",
       "                                               title                    doi  \\\n",
       "0  Clinical features of culture-proven Mycoplasma...  10.1186/1471-2334-1-6   \n",
       "1  Nitric oxide: a pro-inflammatory mediator in l...           10.1186/rr14   \n",
       "2    Surfactant protein-D and pulmonary host defense           10.1186/rr19   \n",
       "3               Role of endothelin-1 in lung disease           10.1186/rr44   \n",
       "4  Gene expression in epithelial cells in respons...           10.1186/rr61   \n",
       "\n",
       "      pmcid   pubmed_id license  \\\n",
       "0  PMC35282  11472636.0   no-cc   \n",
       "1  PMC59543  11667967.0   no-cc   \n",
       "2  PMC59549  11667972.0   no-cc   \n",
       "3  PMC59574  11686871.0   no-cc   \n",
       "4  PMC59580  11686888.0   no-cc   \n",
       "\n",
       "                                            abstract publish_time  ...  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...   2001-07-04  ...   \n",
       "1  Inflammatory diseases of the respiratory tract...   2000-08-15  ...   \n",
       "2  Surfactant protein-D (SP-D) participates in th...   2000-08-25  ...   \n",
       "3  Endothelin-1 (ET-1) is a 21 amino acid peptide...   2001-02-22  ...   \n",
       "4  Respiratory syncytial virus (RSV) and pneumoni...   2001-05-11  ...   \n",
       "\n",
       "  who_covidence_id arxiv_id  \\\n",
       "0              NaN      NaN   \n",
       "1              NaN      NaN   \n",
       "2              NaN      NaN   \n",
       "3              NaN      NaN   \n",
       "4              NaN      NaN   \n",
       "\n",
       "                                      pdf_json_files  \\\n",
       "0  document_parses/pdf_json/d1aafb70c066a2068b027...   \n",
       "1  document_parses/pdf_json/6b0567729c2143a66d737...   \n",
       "2  document_parses/pdf_json/06ced00a5fc04215949aa...   \n",
       "3  document_parses/pdf_json/348055649b6b8cf2b9a37...   \n",
       "4  document_parses/pdf_json/5f48792a5fa08bed9f560...   \n",
       "\n",
       "                               pmc_json_files  \\\n",
       "0  document_parses/pmc_json/PMC35282.xml.json   \n",
       "1  document_parses/pmc_json/PMC59543.xml.json   \n",
       "2  document_parses/pmc_json/PMC59549.xml.json   \n",
       "3  document_parses/pmc_json/PMC59574.xml.json   \n",
       "4  document_parses/pmc_json/PMC59580.xml.json   \n",
       "\n",
       "                                                 url s2_id Diffusivité HTA  \\\n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...   NaN               0   \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...   NaN               0   \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...   NaN               0   \n",
       "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...   NaN               0   \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...   NaN               0   \n",
       "\n",
       "  FreqTitre HTA  FreqAbstrac HTA  FreqTexte HTA  \n",
       "0             0                0              0  \n",
       "1             0                0              0  \n",
       "2             0                0              0  \n",
       "3             0                0              0  \n",
       "4             0                0              0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_full_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>...</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>s2_id</th>\n",
       "      <th>Diffusivité HTA</th>\n",
       "      <th>FreqTitre HTA</th>\n",
       "      <th>FreqAbstrac HTA</th>\n",
       "      <th>FreqTexte HTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1183</td>\n",
       "      <td>2fd5op27</td>\n",
       "      <td>94f391ebd1b25ac7fb8159d7b24b7414c582a630; 3154...</td>\n",
       "      <td>PMC</td>\n",
       "      <td>A Simulation Optimization Approach to Epidemic...</td>\n",
       "      <td>10.1371/journal.pone.0067164</td>\n",
       "      <td>PMC3694918</td>\n",
       "      <td>23826222.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>Reliable forecasts of influenza can aid in the...</td>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/94f391ebd1b25ac7fb815...</td>\n",
       "      <td>document_parses/pmc_json/PMC3694918.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid                                                sha source_x  \\\n",
       "1183  2fd5op27  94f391ebd1b25ac7fb8159d7b24b7414c582a630; 3154...      PMC   \n",
       "\n",
       "                                                  title  \\\n",
       "1183  A Simulation Optimization Approach to Epidemic...   \n",
       "\n",
       "                               doi       pmcid   pubmed_id license  \\\n",
       "1183  10.1371/journal.pone.0067164  PMC3694918  23826222.0   cc-by   \n",
       "\n",
       "                                               abstract publish_time  ...  \\\n",
       "1183  Reliable forecasts of influenza can aid in the...   2013-06-27  ...   \n",
       "\n",
       "     who_covidence_id arxiv_id  \\\n",
       "1183              NaN      NaN   \n",
       "\n",
       "                                         pdf_json_files  \\\n",
       "1183  document_parses/pdf_json/94f391ebd1b25ac7fb815...   \n",
       "\n",
       "                                    pmc_json_files  \\\n",
       "1183  document_parses/pmc_json/PMC3694918.xml.json   \n",
       "\n",
       "                                                    url s2_id Diffusivité HTA  \\\n",
       "1183  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...   NaN               0   \n",
       "\n",
       "     FreqTitre HTA  FreqAbstrac HTA  FreqTexte HTA  \n",
       "1183             0                0              0  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'document_parses/pmc_json/PMC3694918.xml.json'\n",
    "meta_df_full_text.loc[lambda df: df['pmc_json_files'] == path] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.matching()\n",
    "sc.scoring()\n",
    "print(sc.score_dif, sc.score_fr_doc, sc.score_fr_title, sc.score_fr_abstract)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
