{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Volumes/Samsung_T5/JULIETTE/data-CORD'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche du meilleur article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouverture du fichier contenant les metadatas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = f'{root_path}/metadata.csv'\n",
    "metadata_processed_path=f'{root_path}/metadata_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(metadata_path)\n",
    "#meta_df = pd.read_csv(metadata_processed_path)\n",
    "meta_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut relier les articles au fichier des metadatas. Cela est possible grâce aux colonnes (\"pdf_json_files\" et \"pmc_json_files\"). La fonction ci-dessous permet d'ouvrir un article en donnant le chemin d'accès (que l'on récupère dans les métadatas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_article(path):\n",
    "    file=open(root_path+\"/\"+path,'r')\n",
    "    article=json.load(file)\n",
    "    file.close()\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text(article):\n",
    "    text_list = []\n",
    "    for entry in article['body_text']:\n",
    "        text_list.append(entry['text'])\n",
    "        text_list.append(\"\\n\")\n",
    "    \n",
    "    text_full=''.join(text_list)\n",
    "    return text_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=meta_df[\"pdf_json_files\"][0]\n",
    "article=open_article(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critères de sélection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va distinguer deux catégories d'articles, ceux ayant un texte complet et ceux n'en n'ayant pas.\n",
    "\n",
    "Pour noter un article on va prendre en compte :\n",
    "- sa date de parution\n",
    "- la présence des mots-clés dans le titre, l'abstract et le texte complet avec des poids différents. Cette notation doit dépendre de la taille du texte voir du regroupement\n",
    "- le nombre de citations (pas présent dans les métadonnées mais à récupérer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date de parution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(x):\n",
    "    try:\n",
    "        return int(x[:4])\n",
    "    except TypeError:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df[\"date\"]=meta_df[\"publish_time\"].apply(lambda x: date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df[\"date\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=meta_df[\"date\"].value_counts().plot(kind='bar',figsize=(12,10))\n",
    "ax.set_title(\"date de publication\")\n",
    "ax.set_xlabel(\"année\")\n",
    "ax.set_ylabel(\"nombre de publications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut remarquer une explosion des publications en 2020 (ce qui est normal, c'est un corpus rassemblant des articles sur le COVID).\n",
    "\n",
    "La note sur le critère de parution doit être d'autant plus faible que l'article à été publié il y a longtemps. Ainsi on peut appliquer la notation :\n",
    "$$note=\\frac{1}{2020-AnnéePublication+1}$$\n",
    "Ainsi un article publié en 2020 aura 1, en 2019 aura 1/2 et en 2011 aura 0.1\n",
    "Remarque: ce critère est peut être un peu trop sélectif et à tendance à défavoriser énormément les anciens article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critère_date(date):\n",
    "    try:\n",
    "        return 1/(2020-date+1)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df[\"note_date\"]=meta_df[\"date\"].apply(lambda x:critère_date(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critère sur les mots-clés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour savoir si un article traite potentiellement d'un sujet on prend en compte l'abstract, le titre et le texte complet (quand il y en a un). Les poids de la présence des mots-clés dans ceux-ci ne doivent pas être les mêmes.\n",
    "\n",
    "On utilise la fréquence pour noter la présence d'un mot clé (dans le titre, l'abstract ou le texte complet). Naturellement comme en longueur titre>abstract>texte alors les fréquences seront largement plus fortes dans le titre.\n",
    "\n",
    "Pour effectuer la recherche, il faut utiliser une \"lemmatisation\" et une élimination des tirets/majuscules pour éviter de rater certain mots car leur forme change. On applique le processus sur la recherche et les textes.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à faire si besoin\n",
    "#nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "stop=stopwords.words('english')\n",
    "\n",
    "def preprocessing(x): #tokenisation,stop-words,lemmatization ...\n",
    "    clean = re.sub(r'['+string.punctuation + '’—”'+']', \"\", x.lower())\n",
    "    clean_text= re.sub(r'\\W+', ' ', clean)\n",
    "    a=\"\"\n",
    "    for i in clean_text.split():\n",
    "        if i not in stop :\n",
    "            a+=str(lemmatizer.lemmatize(i))+' '\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé de nouvelles colonnes à partir du titre et de l'abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df[\"title_process\"]=meta_df[\"title\"].apply(lambda x: preprocessing(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df[\"abstract_process\"]=meta_df[\"abstract\"].apply(lambda x: preprocessing(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_df.to_csv(root_path+\"/metadata_processed.csv\") à décommenter lors de la première ouverture, permet de ne pas avoir à refaire toutes les transformations plus tard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé le compteur qui donne la fréquence des mots-clés dans l'abstract (ou le texte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(keywords,text): #keywords est une phrase\n",
    "    keys=preprocessing(keywords).split()\n",
    "    text=str(text)\n",
    "    if text==\"NaN\": #élimine \n",
    "        return -1\n",
    "    a=text.split()\n",
    "    if len(a)==0:\n",
    "        return 0\n",
    "    c=0\n",
    "    for i in a:\n",
    "        if i in keys:\n",
    "            c+=1\n",
    "    \n",
    "    return c/len(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_title(keywords,text): #keywords est une phrase\n",
    "    keys=preprocessing(keywords).split()\n",
    "    text=str(text)\n",
    "    if text==\"NaN\":\n",
    "        return -1\n",
    "    a=text.split()\n",
    "    if len(a)==0:\n",
    "        return 0\n",
    "    c=0\n",
    "    for i in keys:\n",
    "        if i in a:\n",
    "            c+=1\n",
    "    \n",
    "    return c/len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_short=meta_df[0:1000].copy() #on se limite aux 1000 premiers pour les tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords=\"factor risk smoking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_short[\"freq_title\"]=meta_df_short[\"title_process\"].apply(lambda x:counter_title(keywords,x))\n",
    "meta_df_short[\"freq_abstract\"]=meta_df_short[\"abstract_process\"].apply(lambda x:counter(keywords,x))\n",
    "meta_df_short[\"freq_added\"]=meta_df_short[[\"freq_title\",\"freq_abstract\"]].apply(lambda x: x[\"freq_title\"]+x[\"freq_abstract\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On additionne maintenant les notes et on trie par ordre décroissant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_short[\"note\"]=meta_df_short[[\"freq_added\",\"note_date\"]].apply(lambda x: x[\"freq_added\"]+x[\"note_date\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_sorted=meta_df_short.sort_values(by=[\"note\"],ascending=False)\n",
    "meta_df_sorted[[\"title\",\"date\",\"freq_added\",\"note\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre de citations\n",
    "On prend en compte le nombre d'articles sur lesquels s'appuie notre article à noter. Plus celui-ci citera des articles, meilleure sera sa note. Pour la note on peut imaginer se baser sur l'article ayant le plus de citations pour ensuite noter les autres par rapport à lui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_full_text(x):\n",
    "    if x[\"pdf_json_files\"]==True and x[\"pmc_json_files\"]==True:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_bool=meta_df_short[[\"pdf_json_files\",\"pmc_json_files\"]].isnull()\n",
    "meta_bool[\"has_full\"]=meta_bool.apply(lambda x:has_full_text(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text=meta_df_short.loc[meta_bool[\"has_full\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a 58 456 articles qui ont des textes complets. On a déjà une fonction qui à partir d'un chemin d'accès ouvre un article, on crée une fonction qui fait appel à celle-ci.\n",
    "\n",
    "Une fois que l'article est ouvert on accède au nombre de référence par \"ref_entries\" et \"bib_entries\". Faut-il prendre en compte le nombre de citations ou de référence ?\n",
    "- référence : sur quoi se base le travail\n",
    "- citation : allusion à un travail déjà accompli \n",
    "\n",
    "Il semble qu'il faille plutôt prendre en compte plutot le nombre de citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(path):\n",
    "    a=\"\"\n",
    "    for i in range (len(path)):\n",
    "        if path[i]==\";\":\n",
    "            break\n",
    "        a+=path[i]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ref=set()\n",
    "dico_ref=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ref(article):\n",
    "    ref=article[\"bib_entries\"]\n",
    "\n",
    "    for i in ref.keys():\n",
    "        title=preprocessing(ref[i][\"title\"])\n",
    "        if title in set_ref:\n",
    "            dico_ref[title]+=1\n",
    "        else:\n",
    "            dico_ref[title]=1\n",
    "            set_ref.add(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ref(x):\n",
    "    try:\n",
    "        path=x[\"pdf_json_files\"]\n",
    "        article=open_article(get_path(str(path)))\n",
    "       \n",
    "    except FileNotFoundError:\n",
    "        path=x[\"pmc_json_files\"]\n",
    "        article=open_article(get_path(str(path)))\n",
    "    add_ref(article)\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_ref=dict()\n",
    "set_ref=set()\n",
    "meta_df_full_text[\"ref\"]=meta_df_full_text[[\"pdf_json_files\",\"pmc_json_files\"]].apply(lambda x: count_ref(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_ref(x):\n",
    "    title=x\n",
    "    if title in set_ref:\n",
    "        return dico_ref[title]\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text[\"nb_ref_linked\"]=meta_df_full_text[\"title_process\"].apply(lambda x: link_ref(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text.sort_values(by=[\"nb_ref_linked\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"path=meta_df[\"pdf_json_files\"][0]\n",
    "article=open_article(path)\n",
    "add_ref(article)\n",
    "print(dico_ref)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste=[]\n",
    "for i in dico_ref.keys():\n",
    "    liste.append(dico_ref[i])\n",
    "print(max(liste))\n",
    "print(len(dico_ref))\n",
    "len(set_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text[\"nb_ref\"]=meta_df_full_text[[\"pdf_json_files\",\"pmc_json_files\"]].apply(lambda x: get_ref(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text[\"nb_ref\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text.to_csv(root_path+\"/metadata_processed_full_text.csv\") #enregistrement du tableau avec les nouvelles informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait une notation linéaire entre celui ayant le plus de référence (il a une note de 1 alors que celui en ayant moins à une note de 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ref=meta_df_full_text[\"nb_ref\"].max()\n",
    "print(max_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text[\"note_ref\"]=meta_df_full_text[\"nb_ref\"].apply(lambda x:x/max_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text[\"note_ref\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette notation ne semble pas très cohérente (il semble avoir une publication avec un très très grands nombre de référence ce qui fausse le tout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_full_text.sort_values(by=[\"nb_ref\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du dictionnaire des références"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=article[\"bib_entries\"]\n",
    "print(ref)\n",
    "#for i in ref.keys():\n",
    "#    print(ref[i][\"title\"]+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation du titre et abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(x):\n",
    "    a=\"\"\n",
    "    for i in x.split():\n",
    "        if i not in stop :\n",
    "            a+=i+' '\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(article):\n",
    "    clean1 = re.sub(r'['+string.punctuation + '’—”'+']', \"\", article.lower())\n",
    "    return re.sub(r'\\W+', ' ', clean1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lem(x):\n",
    "    a=\"\"\n",
    "    for i in x.split():\n",
    "        a+=str(lemmatizer.lemmatize(i))+\" \"\n",
    "    return a\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant transformer les abstracts et les titres pour qu'ils ne contiennent plus de ponctuation, plus de tirets ni de mots de liaison. On peut utiliser de plus un tokennizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3=meta_df2.drop(columns=['sha', 'source_x','doi', 'pmcid', 'pubmed_id','license', 'publish_time', 'authors', 'journal', 'mag_id','who_covidence_id', 'arxiv_id', 'pdf_json_files', 'pmc_json_files','url', 's2_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3=meta_df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3[\"abstract_token\"]=meta_df3[\"abstract\"].apply(lambda x :clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3[\"title_token\"]=meta_df3[\"title\"].apply(lambda x :clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3.drop(columns=[\"title\",\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant il faut créer un dictionnaire qui contient l'ensemble des mots puis faire un décompte des mots pour chaque article afin d'obtenir un tableau de nombre plus facilement interpretable.\n",
    "Il faut aussi enlever les stopwords qui ne permettent pas de différencier les articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3[\"title_stop\"]=meta_df3[\"title_token\"].apply(lambda x:remove_stopwords(x))\n",
    "meta_df3[\"abstract_stop\"]=meta_df3[\"abstract_token\"].apply(lambda x:remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les mots les plus fréquents ne sont pas surprenants (Covid, patient...) et n'apprennent pas grand chose. \n",
    "\n",
    "Est-ce qu'on pourrait supprimer les mots (covid, sarscov2, coronavirus) car tous les articles parlent a priori du sujet) ?\n",
    "\n",
    "\n",
    "On a des articles \"serieux\" donc on suppose qu'il n'y a pas de fautes d'orthographes (du moins que la quantité est négligeable).\n",
    "\n",
    "\"freq\" est un tableau qui pour chaque mot à son nombre d'apparition dans l'ensemble du corpus.\n",
    "Il faudrait la même chose (à deux dimensions) pour chaque article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3[\"title_lem\"]=meta_df3[\"title_stop\"].apply(lambda x:lem(x))\n",
    "meta_df3[\"abstract_lem\"]=meta_df3[\"abstract_stop\"].apply(lambda x:lem(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq=pd.Series(''.join(meta_df3[\"abstract_lem\"]).split()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "#tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts= cv.fit_transform(meta_df3[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text_counts est une matrice, chaque ligne représente un titre et chaque colonne un mot. Ainsi le coefficient ij de le matrice est le nombre de fois que le mot n°j est contenu dans le titre n°i.\n",
    "\n",
    "Comment à partir de la matrice connaitre de quel mot on parle ? Je pense que cela n'est pas utile (c'est juste une visualisation abstraite à exploiter par l'algorithme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "tfidf = tfidf_vectorizer.fit_transform(meta_df3[\"title\"])\n",
    "\n",
    "kmeans = KMeans(n_clusters=10).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
